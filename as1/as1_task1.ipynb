{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322864f7",
   "metadata": {},
   "source": [
    "### To DO:\n",
    "- Hyperparameters for optimizers\n",
    "- Possibly test all parameters at the same time\n",
    "- Apply best to CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb2b764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.14.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.14.0)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Obtaining dependency information for tensorflow[and-cuda] from https://files.pythonhosted.org/packages/cd/4c/9ccf0ac5fd00372146890b801c9b9912269ffe0d208115b75c7dc11e7edc/tensorflow-2.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow-2.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (2.6 kB)\n",
      "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow-macos==2.13.1 (from tensorflow[and-cuda])\n",
      "  Obtaining dependency information for tensorflow-macos==2.13.1 from https://files.pythonhosted.org/packages/c0/d1/d309dea6e67e1b8037f607872486eb67a1ff64fb91a96149086dbdc46ca4/tensorflow_macos-2.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow_macos-2.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (23.5.26)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-macos==2.13.1->tensorflow[and-cuda])\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.3.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.1->tensorflow[and-cuda])\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.59.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-macos==2.13.1->tensorflow[and-cuda])\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-macos==2.13.1->tensorflow[and-cuda])\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-macos==2.13.1->tensorflow[and-cuda])\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/vanbuncha/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.1->tensorflow[and-cuda]) (3.2.2)\n",
      "Downloading tensorflow_macos-2.13.1-cp311-cp311-macosx_12_0_arm64.whl (189.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow-2.13.1-cp311-cp311-macosx_12_0_arm64.whl (1.9 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, tensorflow-estimator, keras, gast, tensorboard, tensorflow-macos, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.14.0\n",
      "    Uninstalling tensorflow-estimator-2.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.14.0\n",
      "    Uninstalling keras-2.14.0:\n",
      "      Successfully uninstalled keras-2.14.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.4\n",
      "    Uninstalling gast-0.5.4:\n",
      "      Successfully uninstalled gast-0.5.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.14.1\n",
      "    Uninstalling tensorboard-2.14.1:\n",
      "      Successfully uninstalled tensorboard-2.14.1\n",
      "  Attempting uninstall: tensorflow-macos\n",
      "    Found existing installation: tensorflow-macos 2.14.0\n",
      "    Uninstalling tensorflow-macos-2.14.0:\n",
      "      Successfully uninstalled tensorflow-macos-2.14.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.14.0\n",
      "    Uninstalling tensorflow-2.14.0:\n",
      "      Successfully uninstalled tensorflow-2.14.0\n",
      "Successfully installed gast-0.4.0 keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-macos-2.13.1 typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "#! pip install keras\n",
    "#! pip install tensorflow\n",
    "#! pip install torch\n",
    "! pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83a6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# initializers\n",
    "from keras.initializers import Zeros  \n",
    "from keras.initializers import RandomNormal, RandomUniform  \n",
    "from keras.initializers import glorot_normal, glorot_uniform \n",
    "from keras.initializers import he_normal, he_uniform  \n",
    "from keras.initializers import lecun_normal, lecun_uniform  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad34711",
   "metadata": {},
   "source": [
    "# Task 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6373974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  1/469 [..............................] - ETA: 1:26 - loss: 2.3134 - accuracy: 0.1328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 11:16:47.306747: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2429 - accuracy: 0.9250 - val_loss: 0.1168 - val_accuracy: 0.9647\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1045 - accuracy: 0.9685 - val_loss: 0.0815 - val_accuracy: 0.9750\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0747 - accuracy: 0.9775 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0704 - val_accuracy: 0.9820\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0513 - accuracy: 0.9850 - val_loss: 0.0726 - val_accuracy: 0.9809\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9875 - val_loss: 0.0761 - val_accuracy: 0.9806\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 0.0818 - val_accuracy: 0.9823\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0713 - val_accuracy: 0.9829\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.0821 - val_accuracy: 0.9830\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0806 - val_accuracy: 0.9844\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 0.0904 - val_accuracy: 0.9833\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0928 - val_accuracy: 0.9819\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0886 - val_accuracy: 0.9844\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0969 - val_accuracy: 0.9840\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.1086 - val_accuracy: 0.9837\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.1032 - val_accuracy: 0.9835\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.1059 - val_accuracy: 0.9838\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.1128 - val_accuracy: 0.9842\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.1181 - val_accuracy: 0.9852\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.1141 - val_accuracy: 0.9847\n",
      "Test loss: 0.11408448219299316\n",
      "Test accuracy: 0.9847000241279602\n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp.py\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c74b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 25s 52ms/step - loss: 2.2751 - accuracy: 0.1553 - val_loss: 2.2429 - val_accuracy: 0.3103\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 2.2230 - accuracy: 0.2540 - val_loss: 2.1777 - val_accuracy: 0.4576\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 2.1542 - accuracy: 0.3497 - val_loss: 2.0890 - val_accuracy: 0.5476\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 29s 61ms/step - loss: 2.0601 - accuracy: 0.4325 - val_loss: 1.9708 - val_accuracy: 0.6110\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 1.9393 - accuracy: 0.4958 - val_loss: 1.8177 - val_accuracy: 0.6687\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 1.7902 - accuracy: 0.5430 - val_loss: 1.6320 - val_accuracy: 0.7102\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 1.6211 - accuracy: 0.5849 - val_loss: 1.4297 - val_accuracy: 0.7413\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 1.4563 - accuracy: 0.6162 - val_loss: 1.2366 - val_accuracy: 0.7676\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 31s 67ms/step - loss: 1.3038 - accuracy: 0.6428 - val_loss: 1.0707 - val_accuracy: 0.7861\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 32s 67ms/step - loss: 1.1812 - accuracy: 0.6651 - val_loss: 0.9401 - val_accuracy: 0.8038\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 1.0862 - accuracy: 0.6816 - val_loss: 0.8419 - val_accuracy: 0.8137\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 37s 78ms/step - loss: 1.0092 - accuracy: 0.6990 - val_loss: 0.7661 - val_accuracy: 0.8221\n",
      "Test loss: 0.7661228775978088\n",
      "Test accuracy: 0.8220999836921692\n"
     ]
    }
   ],
   "source": [
    "# mnist_cnn.py\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2ee6",
   "metadata": {},
   "source": [
    "# Task  1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5ad813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1122 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_46211/1700375211.py:62: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2516 - accuracy: 0.9227 - val_loss: 0.1124 - val_accuracy: 0.9649\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1039 - accuracy: 0.9684 - val_loss: 0.0825 - val_accuracy: 0.9750\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.9771 - val_loss: 0.0771 - val_accuracy: 0.9768\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.0750 - val_accuracy: 0.9793\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0500 - accuracy: 0.9850 - val_loss: 0.0857 - val_accuracy: 0.9774\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.0765 - val_accuracy: 0.9817\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 0.0801 - val_accuracy: 0.9812\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.0827 - val_accuracy: 0.9816\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0922 - val_accuracy: 0.9809\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0911 - val_accuracy: 0.9807\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.1115 - val_accuracy: 0.9810\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.1025 - val_accuracy: 0.9826\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0914 - val_accuracy: 0.9837\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0988 - val_accuracy: 0.9837\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.1127 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.1334 - val_accuracy: 0.9795\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.1162 - val_accuracy: 0.9836\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.1152 - val_accuracy: 0.9831\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.1304 - val_accuracy: 0.9815\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.1280 - val_accuracy: 0.9830\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2671 - accuracy: 0.9169 - val_loss: 0.1349 - val_accuracy: 0.9589\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1059 - accuracy: 0.9684 - val_loss: 0.0826 - val_accuracy: 0.9735\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9766 - val_loss: 0.0698 - val_accuracy: 0.9793\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9818 - val_loss: 0.0858 - val_accuracy: 0.9772\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0515 - accuracy: 0.9846 - val_loss: 0.0742 - val_accuracy: 0.9807\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.0820 - val_accuracy: 0.9808\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.0773 - val_accuracy: 0.9812\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.0913 - val_accuracy: 0.9789\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.1009 - val_accuracy: 0.9786\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.0943 - val_accuracy: 0.9813\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.0902 - val_accuracy: 0.9833\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.1032 - val_accuracy: 0.9827\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 0.1180 - val_accuracy: 0.9802\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1185 - val_accuracy: 0.9802\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.1094 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.1132 - val_accuracy: 0.9823\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.1156 - val_accuracy: 0.9837\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.1282 - val_accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.1382 - val_accuracy: 0.9830\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.1559 - val_accuracy: 0.9800\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2466 - accuracy: 0.9252 - val_loss: 0.1124 - val_accuracy: 0.9646\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1030 - accuracy: 0.9685 - val_loss: 0.0840 - val_accuracy: 0.9738\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 0.0866 - val_accuracy: 0.9746\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.0717 - val_accuracy: 0.9812\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0526 - accuracy: 0.9847 - val_loss: 0.0626 - val_accuracy: 0.9821\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.0769 - val_accuracy: 0.9825\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.0742 - val_accuracy: 0.9809\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0818 - val_accuracy: 0.9828\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0915 - val_accuracy: 0.9818\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0816 - val_accuracy: 0.9829\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.0955 - val_accuracy: 0.9817\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0995 - val_accuracy: 0.9820\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0990 - val_accuracy: 0.9820\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0254 - accuracy: 0.9929 - val_loss: 0.1094 - val_accuracy: 0.9817\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.1081 - val_accuracy: 0.9825\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.1341 - val_accuracy: 0.9807\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.1271 - val_accuracy: 0.9829\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.1231 - val_accuracy: 0.9823\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.1333 - val_accuracy: 0.9835\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.1205 - val_accuracy: 0.9839\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "3         GlorotUniform   0.120519         0.9839\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2454 - accuracy: 0.9236 - val_loss: 0.1072 - val_accuracy: 0.9664\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9692 - val_loss: 0.0834 - val_accuracy: 0.9748\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9773 - val_loss: 0.0810 - val_accuracy: 0.9780\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.0713 - val_accuracy: 0.9800\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9854 - val_loss: 0.0661 - val_accuracy: 0.9817\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9868 - val_loss: 0.0743 - val_accuracy: 0.9816\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.9890 - val_loss: 0.0804 - val_accuracy: 0.9800\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.0862 - val_accuracy: 0.9830\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.0898 - val_accuracy: 0.9824\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0857 - val_accuracy: 0.9812\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.0899 - val_accuracy: 0.9829\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.0861 - val_accuracy: 0.9850\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0243 - accuracy: 0.9934 - val_loss: 0.1048 - val_accuracy: 0.9850\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.1041 - val_accuracy: 0.9828\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.1142 - val_accuracy: 0.9821\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.1132 - val_accuracy: 0.9810\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.1182 - val_accuracy: 0.9827\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.1188 - val_accuracy: 0.9817\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.1258 - val_accuracy: 0.9832\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.1184 - val_accuracy: 0.9835\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "3         GlorotUniform   0.120519         0.9839\n",
      "4          GlorotNormal   0.118364         0.9835\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2469 - accuracy: 0.9248 - val_loss: 0.1066 - val_accuracy: 0.9687\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1035 - accuracy: 0.9683 - val_loss: 0.0935 - val_accuracy: 0.9725\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0760 - accuracy: 0.9770 - val_loss: 0.0832 - val_accuracy: 0.9767\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.0791 - val_accuracy: 0.9785\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 0.0913 - val_accuracy: 0.9786\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.0796 - val_accuracy: 0.9797\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.0795 - val_accuracy: 0.9818\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0836 - val_accuracy: 0.9820\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 0.0776 - val_accuracy: 0.9831\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0277 - accuracy: 0.9922 - val_loss: 0.0814 - val_accuracy: 0.9838\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0862 - val_accuracy: 0.9826\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.0959 - val_accuracy: 0.9835\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.1178 - val_accuracy: 0.9793\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.1139 - val_accuracy: 0.9824\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 0.1247 - val_accuracy: 0.9804\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.1137 - val_accuracy: 0.9838\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.0991 - val_accuracy: 0.9843\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.1159 - val_accuracy: 0.9822\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.1206 - val_accuracy: 0.9836\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1342 - val_accuracy: 0.9828\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "3         GlorotUniform   0.120519         0.9839\n",
      "4          GlorotNormal   0.118364         0.9835\n",
      "5              HeNormal   0.134194         0.9828\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2502 - accuracy: 0.9232 - val_loss: 0.1558 - val_accuracy: 0.9480\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1030 - accuracy: 0.9684 - val_loss: 0.0999 - val_accuracy: 0.9690\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0760 - accuracy: 0.9763 - val_loss: 0.0806 - val_accuracy: 0.9770\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 0.0807 - val_accuracy: 0.9783\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 0.0741 - val_accuracy: 0.9815\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.0768 - val_accuracy: 0.9816\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.0823 - val_accuracy: 0.9797\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 0.0814 - val_accuracy: 0.9814\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0891 - val_accuracy: 0.9825\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0928 - val_accuracy: 0.9820\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0981 - val_accuracy: 0.9797\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0970 - val_accuracy: 0.9815\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.1117 - val_accuracy: 0.9813\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.1007 - val_accuracy: 0.9821\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.1115 - val_accuracy: 0.9825\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.1482 - val_accuracy: 0.9802\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.1239 - val_accuracy: 0.9813\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.1150 - val_accuracy: 0.9834\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.1167 - val_accuracy: 0.9840\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.1277 - val_accuracy: 0.9831\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "3         GlorotUniform   0.120519         0.9839\n",
      "4          GlorotNormal   0.118364         0.9835\n",
      "5              HeNormal   0.134194         0.9828\n",
      "6             HeUniform   0.127728         0.9831\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_29 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2497 - accuracy: 0.9229 - val_loss: 0.1098 - val_accuracy: 0.9643\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9682 - val_loss: 0.0878 - val_accuracy: 0.9749\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0778 - accuracy: 0.9770 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.0741 - val_accuracy: 0.9816\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.9844 - val_loss: 0.0804 - val_accuracy: 0.9794\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 0.0755 - val_accuracy: 0.9809\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.0753 - val_accuracy: 0.9809\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0867 - val_accuracy: 0.9815\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9907 - val_loss: 0.0826 - val_accuracy: 0.9820\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.0993 - val_accuracy: 0.9809\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0881 - val_accuracy: 0.9834\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.1034 - val_accuracy: 0.9823\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0978 - val_accuracy: 0.9832\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.1063 - val_accuracy: 0.9817\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.1098 - val_accuracy: 0.9817\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.1219 - val_accuracy: 0.9820\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.1092 - val_accuracy: 0.9835\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.1131 - val_accuracy: 0.9827\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.1120 - val_accuracy: 0.9850\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.1217 - val_accuracy: 0.9837\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "3         GlorotUniform   0.120519         0.9839\n",
      "4          GlorotNormal   0.118364         0.9835\n",
      "5              HeNormal   0.134194         0.9828\n",
      "6             HeUniform   0.127728         0.9831\n",
      "7           LecunNormal   0.121682         0.9837\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2506 - accuracy: 0.9232 - val_loss: 0.1075 - val_accuracy: 0.9669\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9679 - val_loss: 0.0896 - val_accuracy: 0.9716\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0736 - accuracy: 0.9775 - val_loss: 0.0777 - val_accuracy: 0.9781\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0619 - accuracy: 0.9806 - val_loss: 0.0688 - val_accuracy: 0.9810\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9811\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0453 - accuracy: 0.9868 - val_loss: 0.0833 - val_accuracy: 0.9802\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.0802 - val_accuracy: 0.9806\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0356 - accuracy: 0.9894 - val_loss: 0.0882 - val_accuracy: 0.9833\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.0854 - val_accuracy: 0.9817\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.0884 - val_accuracy: 0.9813\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0935 - val_accuracy: 0.9836\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.1079 - val_accuracy: 0.9798\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.1139 - val_accuracy: 0.9834\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.1163 - val_accuracy: 0.9819\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.1045 - val_accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.1173 - val_accuracy: 0.9812\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.1126 - val_accuracy: 0.9837\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.1211 - val_accuracy: 0.9838\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1429 - val_accuracy: 0.9831\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1329 - val_accuracy: 0.9826\n",
      "  Initialization Method  Test Loss  Test Accuracy\n",
      "0                 Zeros   2.301056         0.1135\n",
      "1          RandomNormal   0.128028         0.9830\n",
      "2         RandomUniform   0.155915         0.9800\n",
      "3         GlorotUniform   0.120519         0.9839\n",
      "4          GlorotNormal   0.118364         0.9835\n",
      "5              HeNormal   0.134194         0.9828\n",
      "6             HeUniform   0.127728         0.9831\n",
      "7           LecunNormal   0.121682         0.9837\n",
      "8          LecunUniform   0.132943         0.9826\n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp.py + different initilization methods\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "seed_value = 42\n",
    "results = pd.DataFrame(columns=['Initialization Method', 'Test Loss', 'Test Accuracy'])\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "initilization_methods = [Zeros(), \n",
    "                       RandomNormal(seed=seed_value), \n",
    "                       RandomUniform(seed=seed_value), \n",
    "                       glorot_uniform(seed=seed_value), \n",
    "                       glorot_normal(seed=seed_value), \n",
    "                       he_normal(seed=seed_value), \n",
    "                       he_uniform(seed=seed_value), \n",
    "                       lecun_normal(seed=seed_value), \n",
    "                       lecun_uniform(seed=seed_value)]\n",
    "\n",
    "for method in initilization_methods:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer=method))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer=method))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer=method))\n",
    "\n",
    "    # Extract name of method\n",
    "    method_name = method.__class__.__name__\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    new_result = pd.DataFrame({'Initialization Method': [method_name], 'Test Loss': [score[0]], 'Test Accuracy': [score[1]]})\n",
    "    results = pd.concat([results, new_result], ignore_index=True)\n",
    "    \n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f8cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2468 - accuracy: 0.9243 - val_loss: 0.1054 - val_accuracy: 0.9686\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1013 - accuracy: 0.9687 - val_loss: 0.0765 - val_accuracy: 0.9760\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0764 - accuracy: 0.9770 - val_loss: 0.0789 - val_accuracy: 0.9784\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.0755 - val_accuracy: 0.9789\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0488 - accuracy: 0.9858 - val_loss: 0.0752 - val_accuracy: 0.9812\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 0.0940 - val_accuracy: 0.9734\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 0.0843 - val_accuracy: 0.9804\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0705 - val_accuracy: 0.9830\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.0984 - val_accuracy: 0.9803\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0860 - val_accuracy: 0.9826\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0981 - val_accuracy: 0.9832\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.1031 - val_accuracy: 0.9830\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 0.0941 - val_accuracy: 0.9855\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.1043 - val_accuracy: 0.9830\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.1051 - val_accuracy: 0.9835\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.1278 - val_accuracy: 0.9815\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1279 - val_accuracy: 0.9834\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.1185 - val_accuracy: 0.9827\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.1127 - val_accuracy: 0.9841\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1345 - val_accuracy: 0.9835\n",
      "  Activation Method  Test Loss  Test Accuracy\n",
      "0              relu   0.134513         0.9835\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_41 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_46211/1699284994.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5377 - accuracy: 0.8336 - val_loss: 0.2651 - val_accuracy: 0.9186\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2372 - accuracy: 0.9274 - val_loss: 0.1764 - val_accuracy: 0.9448\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1693 - accuracy: 0.9487 - val_loss: 0.1353 - val_accuracy: 0.9575\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1302 - accuracy: 0.9599 - val_loss: 0.1071 - val_accuracy: 0.9661\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1077 - accuracy: 0.9668 - val_loss: 0.0912 - val_accuracy: 0.9705\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.9722 - val_loss: 0.0980 - val_accuracy: 0.9700\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0797 - accuracy: 0.9755 - val_loss: 0.0777 - val_accuracy: 0.9762\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9782 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0781 - val_accuracy: 0.9766\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.0662 - val_accuracy: 0.9802\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0680 - val_accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0688 - val_accuracy: 0.9793\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 0.0668 - val_accuracy: 0.9817\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.0639 - val_accuracy: 0.9819\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0688 - val_accuracy: 0.9799\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.0745 - val_accuracy: 0.9795\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0639 - val_accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0634 - val_accuracy: 0.9833\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0666 - val_accuracy: 0.9834\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0690 - val_accuracy: 0.9829\n",
      "  Activation Method  Test Loss  Test Accuracy\n",
      "0              relu   0.134513         0.9835\n",
      "1           sigmoid   0.069045         0.9829\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3497 - accuracy: 0.8949 - val_loss: 0.1859 - val_accuracy: 0.9436\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1658 - accuracy: 0.9493 - val_loss: 0.1424 - val_accuracy: 0.9551\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1157 - accuracy: 0.9645 - val_loss: 0.0958 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0899 - accuracy: 0.9713 - val_loss: 0.0865 - val_accuracy: 0.9733\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9769 - val_loss: 0.0840 - val_accuracy: 0.9738\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 0.0788 - val_accuracy: 0.9754\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.9829 - val_loss: 0.0739 - val_accuracy: 0.9772\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.9849 - val_loss: 0.0845 - val_accuracy: 0.9749\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.0722 - val_accuracy: 0.9772\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.0684 - val_accuracy: 0.9794\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0631 - val_accuracy: 0.9809\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0718 - val_accuracy: 0.9797\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.0657 - val_accuracy: 0.9806\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0727 - val_accuracy: 0.9794\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0678 - val_accuracy: 0.9823\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0706 - val_accuracy: 0.9816\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0639 - val_accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0688 - val_accuracy: 0.9820\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0728 - val_accuracy: 0.9804\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0708 - val_accuracy: 0.9818\n",
      "  Activation Method  Test Loss  Test Accuracy\n",
      "0              relu   0.134513         0.9835\n",
      "1           sigmoid   0.069045         0.9829\n",
      "2              tanh   0.070753         0.9818\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_47 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4637 - accuracy: 0.8662 - val_loss: 0.3975 - val_accuracy: 0.8905\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3753 - accuracy: 0.8935 - val_loss: 0.3417 - val_accuracy: 0.9005\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.9001 - val_loss: 0.3255 - val_accuracy: 0.9120\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3385 - accuracy: 0.9044 - val_loss: 0.3136 - val_accuracy: 0.9129\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3323 - accuracy: 0.9065 - val_loss: 0.3152 - val_accuracy: 0.9138\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3257 - accuracy: 0.9077 - val_loss: 0.3252 - val_accuracy: 0.9135\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3237 - accuracy: 0.9089 - val_loss: 0.3029 - val_accuracy: 0.9138\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3195 - accuracy: 0.9113 - val_loss: 0.3097 - val_accuracy: 0.9122\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3159 - accuracy: 0.9107 - val_loss: 0.3238 - val_accuracy: 0.9142\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3139 - accuracy: 0.9118 - val_loss: 0.3392 - val_accuracy: 0.9065\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3131 - accuracy: 0.9123 - val_loss: 0.3170 - val_accuracy: 0.9134\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3099 - accuracy: 0.9124 - val_loss: 0.3255 - val_accuracy: 0.9117\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3103 - accuracy: 0.9128 - val_loss: 0.3227 - val_accuracy: 0.9094\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3104 - accuracy: 0.9126 - val_loss: 0.3084 - val_accuracy: 0.9142\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3095 - accuracy: 0.9136 - val_loss: 0.3228 - val_accuracy: 0.9111\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.9138 - val_loss: 0.3021 - val_accuracy: 0.9183\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3084 - accuracy: 0.9140 - val_loss: 0.3475 - val_accuracy: 0.9015\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.9144 - val_loss: 0.3066 - val_accuracy: 0.9186\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3033 - accuracy: 0.9151 - val_loss: 0.3181 - val_accuracy: 0.9099\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3052 - accuracy: 0.9138 - val_loss: 0.2979 - val_accuracy: 0.9189\n",
      "  Activation Method  Test Loss  Test Accuracy\n",
      "0              relu   0.134513         0.9835\n",
      "1           sigmoid   0.069045         0.9829\n",
      "2              tanh   0.070753         0.9818\n",
      "3            linear   0.297900         0.9189\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.2812 - accuracy: 0.1488 - val_loss: 2.2270 - val_accuracy: 0.1980\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.1072 - accuracy: 0.5396 - val_loss: 1.9324 - val_accuracy: 0.6641\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.8008 - accuracy: 0.5585 - val_loss: 1.5501 - val_accuracy: 0.6675\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5067 - accuracy: 0.5640 - val_loss: 1.2118 - val_accuracy: 0.6774\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2925 - accuracy: 0.5675 - val_loss: 0.9780 - val_accuracy: 0.6857\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1552 - accuracy: 0.5762 - val_loss: 0.8440 - val_accuracy: 0.6864\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0806 - accuracy: 0.5828 - val_loss: 0.7753 - val_accuracy: 0.6973\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0398 - accuracy: 0.5878 - val_loss: 0.7392 - val_accuracy: 0.7151\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0170 - accuracy: 0.5952 - val_loss: 0.7234 - val_accuracy: 0.7323\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9976 - accuracy: 0.6072 - val_loss: 0.7081 - val_accuracy: 0.7363\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9796 - accuracy: 0.6143 - val_loss: 0.6925 - val_accuracy: 0.7516\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9632 - accuracy: 0.6259 - val_loss: 0.6748 - val_accuracy: 0.7773\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9479 - accuracy: 0.6364 - val_loss: 0.6583 - val_accuracy: 0.7903\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9203 - accuracy: 0.6539 - val_loss: 0.6349 - val_accuracy: 0.8168\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8751 - accuracy: 0.6915 - val_loss: 0.5898 - val_accuracy: 0.8499\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8166 - accuracy: 0.7225 - val_loss: 0.5375 - val_accuracy: 0.8646\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7673 - accuracy: 0.7405 - val_loss: 0.4992 - val_accuracy: 0.8656\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7225 - accuracy: 0.7609 - val_loss: 0.4762 - val_accuracy: 0.8669\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7031 - accuracy: 0.7702 - val_loss: 0.4540 - val_accuracy: 0.8747\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6743 - accuracy: 0.7822 - val_loss: 0.4302 - val_accuracy: 0.8897\n",
      "  Activation Method  Test Loss  Test Accuracy\n",
      "0              relu   0.134513         0.9835\n",
      "1           sigmoid   0.069045         0.9829\n",
      "2              tanh   0.070753         0.9818\n",
      "3            linear   0.297900         0.9189\n",
      "4           softmax   0.430244         0.8897\n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp.py + different activation functions\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "seed_value = 42\n",
    "results = pd.DataFrame(columns=['Activation Method', 'Test Loss', 'Test Accuracy'])\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "activation_methods = ['relu', 'sigmoid', 'tanh', 'linear', 'softmax']\n",
    "\n",
    "\n",
    "\n",
    "for method in activation_methods:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=method, input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation=method))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    \n",
    "    method_name = method\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    new_result = pd.DataFrame({'Activation Method': [method_name], 'Test Loss': [score[0]], 'Test Accuracy': [score[1]]})\n",
    "    results = pd.concat([results, new_result], ignore_index=True)\n",
    "    \n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab475863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2458 - accuracy: 0.9270 - val_loss: 0.1036 - val_accuracy: 0.9678\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0968 - accuracy: 0.9701 - val_loss: 0.0735 - val_accuracy: 0.9763\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0710 - accuracy: 0.9776 - val_loss: 0.0756 - val_accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0555 - accuracy: 0.9817 - val_loss: 0.0607 - val_accuracy: 0.9811\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 0.0624 - val_accuracy: 0.9808\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.0694 - val_accuracy: 0.9809\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0613 - val_accuracy: 0.9844\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.0775 - val_accuracy: 0.9815\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0711 - val_accuracy: 0.9828\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0722 - val_accuracy: 0.9837\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0750 - val_accuracy: 0.9822\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0700 - val_accuracy: 0.9835\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0755 - val_accuracy: 0.9819\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0829 - val_accuracy: 0.9814\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0798 - val_accuracy: 0.9830\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0783 - val_accuracy: 0.9839\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0795 - val_accuracy: 0.9833\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0792 - val_accuracy: 0.9834\n",
      "  Optimizer  Test Loss  Test Accuracy\n",
      "0      Adam   0.079151         0.9834\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_59 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  1/469 [..............................] - ETA: 54s - loss: 2.3229 - accuracy: 0.1484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_46211/1283481495.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2457 - accuracy: 0.6788 - val_loss: 0.5536 - val_accuracy: 0.8710\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5371 - accuracy: 0.8493 - val_loss: 0.3799 - val_accuracy: 0.8997\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4273 - accuracy: 0.8769 - val_loss: 0.3245 - val_accuracy: 0.9090\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3772 - accuracy: 0.8909 - val_loss: 0.2941 - val_accuracy: 0.9163\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3439 - accuracy: 0.8996 - val_loss: 0.2735 - val_accuracy: 0.9221\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3178 - accuracy: 0.9083 - val_loss: 0.2549 - val_accuracy: 0.9282\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.9137 - val_loss: 0.2399 - val_accuracy: 0.9330\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2816 - accuracy: 0.9183 - val_loss: 0.2286 - val_accuracy: 0.9355\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2669 - accuracy: 0.9221 - val_loss: 0.2170 - val_accuracy: 0.9385\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2541 - accuracy: 0.9262 - val_loss: 0.2074 - val_accuracy: 0.9411\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2441 - accuracy: 0.9296 - val_loss: 0.1985 - val_accuracy: 0.9428\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2335 - accuracy: 0.9322 - val_loss: 0.1906 - val_accuracy: 0.9453\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2235 - accuracy: 0.9353 - val_loss: 0.1839 - val_accuracy: 0.9461\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2151 - accuracy: 0.9376 - val_loss: 0.1766 - val_accuracy: 0.9492\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2052 - accuracy: 0.9410 - val_loss: 0.1705 - val_accuracy: 0.9510\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1968 - accuracy: 0.9430 - val_loss: 0.1642 - val_accuracy: 0.9527\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1929 - accuracy: 0.9436 - val_loss: 0.1590 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1857 - accuracy: 0.9457 - val_loss: 0.1555 - val_accuracy: 0.9538\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1803 - accuracy: 0.9478 - val_loss: 0.1498 - val_accuracy: 0.9565\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1747 - accuracy: 0.9492 - val_loss: 0.1466 - val_accuracy: 0.9566\n",
      "  Optimizer  Test Loss  Test Accuracy\n",
      "0      Adam   0.079151         0.9834\n",
      "1       SGD   0.146637         0.9566\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2474 - accuracy: 0.9233 - val_loss: 0.0996 - val_accuracy: 0.9704\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.9690 - val_loss: 0.0889 - val_accuracy: 0.9724\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0756 - accuracy: 0.9772 - val_loss: 0.0693 - val_accuracy: 0.9803\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0595 - accuracy: 0.9814 - val_loss: 0.0724 - val_accuracy: 0.9799\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0897 - val_accuracy: 0.9802\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.0860 - val_accuracy: 0.9819\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0836 - val_accuracy: 0.9828\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.0968 - val_accuracy: 0.9796\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.0955 - val_accuracy: 0.9815\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.0985 - val_accuracy: 0.9827\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.1034 - val_accuracy: 0.9824\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.1266 - val_accuracy: 0.9784\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.1116 - val_accuracy: 0.9827\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.1018 - val_accuracy: 0.9833\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.1248 - val_accuracy: 0.9831\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.1226 - val_accuracy: 0.9831\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.1311 - val_accuracy: 0.9832\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.1183 - val_accuracy: 0.9839\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.1438 - val_accuracy: 0.9826\n",
      "  Optimizer  Test Loss  Test Accuracy\n",
      "0      Adam   0.079151         0.9834\n",
      "1       SGD   0.146637         0.9566\n",
      "2   RMSprop   0.143792         0.9826\n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp.py + different optimizers\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "seed_value = 42\n",
    "results = pd.DataFrame(columns=['Optimizer', 'Test Loss', 'Test Accuracy'])\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "optimizers = [keras.optimizers.Adam, keras.optimizers.SGD, keras.optimizers.RMSprop]\n",
    "\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Use the optimizer's name as method_name\n",
    "    method_name = optimizer.__name__\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    new_result = pd.DataFrame({'Optimizer': [method_name], 'Test Loss': [score[0]], 'Test Accuracy': [score[1]]})\n",
    "    results = pd.concat([results, new_result], ignore_index=True)\n",
    "    \n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db0c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_67 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9252 - val_loss: 0.1259 - val_accuracy: 0.9623\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.9696 - val_loss: 0.0862 - val_accuracy: 0.9737\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9789 - val_loss: 0.0785 - val_accuracy: 0.9761\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.9853 - val_loss: 0.0708 - val_accuracy: 0.9775\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.0728 - val_accuracy: 0.9783\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0634 - val_accuracy: 0.9817\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0645 - val_accuracy: 0.9808\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0635 - val_accuracy: 0.9811\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0646 - val_accuracy: 0.9829\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0741 - val_accuracy: 0.9806\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0696 - val_accuracy: 0.9823\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0784 - val_accuracy: 0.9817\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0791 - val_accuracy: 0.9823\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0820 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0821 - val_accuracy: 0.9825\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0875 - val_accuracy: 0.9824\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1130 - val_accuracy: 0.9782\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0943 - val_accuracy: 0.9824\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 7.2073e-04 - accuracy: 0.9998 - val_loss: 0.0971 - val_accuracy: 0.9816\n",
      "  Regularization Method  Test Loss  Test Accuracy\n",
      "0                  None    0.09708         0.9816\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_69 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  1/469 [..............................] - ETA: 1:14 - loss: 102.6589 - accuracy: 0.1172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_46211/400663256.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 4ms/step - loss: 6.5434 - accuracy: 0.8136 - val_loss: 1.9698 - val_accuracy: 0.8859\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.8520 - accuracy: 0.9057 - val_loss: 1.7738 - val_accuracy: 0.9181\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.7281 - accuracy: 0.9261 - val_loss: 1.6590 - val_accuracy: 0.9393\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.6650 - accuracy: 0.9365 - val_loss: 1.6664 - val_accuracy: 0.9340\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.6227 - accuracy: 0.9452 - val_loss: 1.6120 - val_accuracy: 0.9494\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5930 - accuracy: 0.9508 - val_loss: 1.5967 - val_accuracy: 0.9472\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5721 - accuracy: 0.9538 - val_loss: 1.5608 - val_accuracy: 0.9550\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5553 - accuracy: 0.9570 - val_loss: 1.5443 - val_accuracy: 0.9560\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5406 - accuracy: 0.9598 - val_loss: 1.5522 - val_accuracy: 0.9578\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5272 - accuracy: 0.9625 - val_loss: 1.5388 - val_accuracy: 0.9587\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5169 - accuracy: 0.9647 - val_loss: 1.5244 - val_accuracy: 0.9634\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5074 - accuracy: 0.9658 - val_loss: 1.5115 - val_accuracy: 0.9647\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4993 - accuracy: 0.9680 - val_loss: 1.5036 - val_accuracy: 0.9663\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4919 - accuracy: 0.9693 - val_loss: 1.4929 - val_accuracy: 0.9683\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.4855 - accuracy: 0.9702 - val_loss: 1.5056 - val_accuracy: 0.9646\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4799 - accuracy: 0.9722 - val_loss: 1.4887 - val_accuracy: 0.9683\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4750 - accuracy: 0.9727 - val_loss: 1.4865 - val_accuracy: 0.9670\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.4698 - accuracy: 0.9736 - val_loss: 1.4722 - val_accuracy: 0.9707\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4660 - accuracy: 0.9742 - val_loss: 1.4787 - val_accuracy: 0.9714\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4627 - accuracy: 0.9751 - val_loss: 1.4902 - val_accuracy: 0.9652\n",
      "  Regularization Method  Test Loss  Test Accuracy\n",
      "0                  None   0.097080         0.9816\n",
      "1                    L1   1.490166         0.9652\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7473 - accuracy: 0.9115 - val_loss: 0.2473 - val_accuracy: 0.9498\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2079 - accuracy: 0.9584 - val_loss: 0.2838 - val_accuracy: 0.9192\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1637 - accuracy: 0.9689 - val_loss: 0.1555 - val_accuracy: 0.9669\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1424 - accuracy: 0.9724 - val_loss: 0.1411 - val_accuracy: 0.9705\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1271 - accuracy: 0.9764 - val_loss: 0.1318 - val_accuracy: 0.9739\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1167 - accuracy: 0.9787 - val_loss: 0.1289 - val_accuracy: 0.9742\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1071 - accuracy: 0.9801 - val_loss: 0.1430 - val_accuracy: 0.9668\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1013 - accuracy: 0.9816 - val_loss: 0.1222 - val_accuracy: 0.9757\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9831 - val_loss: 0.1170 - val_accuracy: 0.9773\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0906 - accuracy: 0.9838 - val_loss: 0.1067 - val_accuracy: 0.9808\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0833 - accuracy: 0.9858 - val_loss: 0.1572 - val_accuracy: 0.9656\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0821 - accuracy: 0.9858 - val_loss: 0.1146 - val_accuracy: 0.9759\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0777 - accuracy: 0.9868 - val_loss: 0.1134 - val_accuracy: 0.9785\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0743 - accuracy: 0.9871 - val_loss: 0.1438 - val_accuracy: 0.9685\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0708 - accuracy: 0.9886 - val_loss: 0.1197 - val_accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0688 - accuracy: 0.9886 - val_loss: 0.1102 - val_accuracy: 0.9781\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0652 - accuracy: 0.9895 - val_loss: 0.1167 - val_accuracy: 0.9780\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0629 - accuracy: 0.9899 - val_loss: 0.1164 - val_accuracy: 0.9772\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9903 - val_loss: 0.1150 - val_accuracy: 0.9801\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0586 - accuracy: 0.9909 - val_loss: 0.1085 - val_accuracy: 0.9799\n",
      "  Regularization Method  Test Loss  Test Accuracy\n",
      "0                  None   0.097080         0.9816\n",
      "1                    L1   1.490166         0.9652\n",
      "2                    L2   0.108498         0.9799\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2456 - accuracy: 0.9236 - val_loss: 0.1185 - val_accuracy: 0.9642\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1039 - accuracy: 0.9686 - val_loss: 0.0895 - val_accuracy: 0.9732\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9777 - val_loss: 0.0790 - val_accuracy: 0.9759\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9811 - val_loss: 0.0841 - val_accuracy: 0.9755\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9852 - val_loss: 0.0734 - val_accuracy: 0.9811\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.0731 - val_accuracy: 0.9823\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0369 - accuracy: 0.9890 - val_loss: 0.0838 - val_accuracy: 0.9810\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0832 - val_accuracy: 0.9821\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0896 - val_accuracy: 0.9825\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0889 - val_accuracy: 0.9836\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.0937 - val_accuracy: 0.9823\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.1113 - val_accuracy: 0.9801\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.1081 - val_accuracy: 0.9825\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.1256 - val_accuracy: 0.9822\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.1047 - val_accuracy: 0.9833\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.1118 - val_accuracy: 0.9832\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.1245 - val_accuracy: 0.9817\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.1085 - val_accuracy: 0.9837\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.1173 - val_accuracy: 0.9842\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1345 - val_accuracy: 0.9837\n",
      "  Regularization Method  Test Loss  Test Accuracy\n",
      "0                  None   0.097080         0.9816\n",
      "1                    L1   1.490166         0.9652\n",
      "2                    L2   0.108498         0.9799\n",
      "3               Dropout   0.134471         0.9837\n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp.py + different regularization techniques\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape (10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "seed_value = 42\n",
    "results = pd.DataFrame(columns=['Regularization Method', 'Test Loss', 'Test Accuracy'])\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "regularization_methods = ['None', 'L1', 'L2', 'Dropout']\n",
    "\n",
    "for method in regularization_methods:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "\n",
    "    if method == 'L1':\n",
    "        model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "    elif method == 'L2':\n",
    "        model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "    elif method == 'Dropout':\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Use the regularization method as method_name\n",
    "    method_name = method\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    new_result = pd.DataFrame({'Regularization Method': [method_name], 'Test Loss': [score[0]], 'Test Accuracy': [score[1]]})\n",
    "    results = pd.concat([results, new_result], ignore_index=True)\n",
    "\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03cf34af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/tw9kr3yd4h950rswblzvqc9h0000gn/T/ipykernel_46211/1166043142.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Best Performing Configurations:\n",
      "   Optimizer  Learning Rate Momentum       Epsilon Nesterov Batch Size  \\\n",
      "62       SGD            0.1      0.9  1.000000e-04     True         64   \n",
      "60       SGD            0.1      0.9  1.000000e-04    False         64   \n",
      "58       SGD            0.1      0.9  1.000000e-08     True         64   \n",
      "50       SGD            0.1        0  1.000000e-08     True         64   \n",
      "54       SGD            0.1        0  1.000000e-04     True         64   \n",
      "\n",
      "    Test Loss  Test Accuracy  \n",
      "62   0.072707         0.9780  \n",
      "60   0.073003         0.9778  \n",
      "58   0.070178         0.9777  \n",
      "50   0.073058         0.9767  \n",
      "54   0.075574         0.9765  \n",
      "   Optimizer  Learning Rate Momentum       Epsilon Nesterov Batch Size  \\\n",
      "0       Adam        0.00001        0  1.000000e-08    False         64   \n",
      "1       Adam        0.00001        0  1.000000e-08    False        256   \n",
      "2       Adam        0.00001        0  1.000000e-08     True         64   \n",
      "3       Adam        0.00001        0  1.000000e-08     True        256   \n",
      "4       Adam        0.00001        0  1.000000e-04    False         64   \n",
      "5       Adam        0.00001        0  1.000000e-04    False        256   \n",
      "6       Adam        0.00001        0  1.000000e-04     True         64   \n",
      "7       Adam        0.00001        0  1.000000e-04     True        256   \n",
      "8       Adam        0.00001      0.9  1.000000e-08    False         64   \n",
      "9       Adam        0.00001      0.9  1.000000e-08    False        256   \n",
      "10      Adam        0.00001      0.9  1.000000e-08     True         64   \n",
      "11      Adam        0.00001      0.9  1.000000e-08     True        256   \n",
      "12      Adam        0.00001      0.9  1.000000e-04    False         64   \n",
      "13      Adam        0.00001      0.9  1.000000e-04    False        256   \n",
      "14      Adam        0.00001      0.9  1.000000e-04     True         64   \n",
      "15      Adam        0.00001      0.9  1.000000e-04     True        256   \n",
      "16      Adam        0.10000        0  1.000000e-08    False         64   \n",
      "17      Adam        0.10000        0  1.000000e-08    False        256   \n",
      "18      Adam        0.10000        0  1.000000e-08     True         64   \n",
      "19      Adam        0.10000        0  1.000000e-08     True        256   \n",
      "20      Adam        0.10000        0  1.000000e-04    False         64   \n",
      "21      Adam        0.10000        0  1.000000e-04    False        256   \n",
      "22      Adam        0.10000        0  1.000000e-04     True         64   \n",
      "23      Adam        0.10000        0  1.000000e-04     True        256   \n",
      "24      Adam        0.10000      0.9  1.000000e-08    False         64   \n",
      "25      Adam        0.10000      0.9  1.000000e-08    False        256   \n",
      "26      Adam        0.10000      0.9  1.000000e-08     True         64   \n",
      "27      Adam        0.10000      0.9  1.000000e-08     True        256   \n",
      "28      Adam        0.10000      0.9  1.000000e-04    False         64   \n",
      "29      Adam        0.10000      0.9  1.000000e-04    False        256   \n",
      "30      Adam        0.10000      0.9  1.000000e-04     True         64   \n",
      "31      Adam        0.10000      0.9  1.000000e-04     True        256   \n",
      "32       SGD        0.00001        0  1.000000e-08    False         64   \n",
      "33       SGD        0.00001        0  1.000000e-08    False        256   \n",
      "34       SGD        0.00001        0  1.000000e-08     True         64   \n",
      "35       SGD        0.00001        0  1.000000e-08     True        256   \n",
      "36       SGD        0.00001        0  1.000000e-04    False         64   \n",
      "37       SGD        0.00001        0  1.000000e-04    False        256   \n",
      "38       SGD        0.00001        0  1.000000e-04     True         64   \n",
      "39       SGD        0.00001        0  1.000000e-04     True        256   \n",
      "40       SGD        0.00001      0.9  1.000000e-08    False         64   \n",
      "41       SGD        0.00001      0.9  1.000000e-08    False        256   \n",
      "42       SGD        0.00001      0.9  1.000000e-08     True         64   \n",
      "43       SGD        0.00001      0.9  1.000000e-08     True        256   \n",
      "44       SGD        0.00001      0.9  1.000000e-04    False         64   \n",
      "45       SGD        0.00001      0.9  1.000000e-04    False        256   \n",
      "46       SGD        0.00001      0.9  1.000000e-04     True         64   \n",
      "47       SGD        0.00001      0.9  1.000000e-04     True        256   \n",
      "48       SGD        0.10000        0  1.000000e-08    False         64   \n",
      "49       SGD        0.10000        0  1.000000e-08    False        256   \n",
      "50       SGD        0.10000        0  1.000000e-08     True         64   \n",
      "51       SGD        0.10000        0  1.000000e-08     True        256   \n",
      "52       SGD        0.10000        0  1.000000e-04    False         64   \n",
      "53       SGD        0.10000        0  1.000000e-04    False        256   \n",
      "54       SGD        0.10000        0  1.000000e-04     True         64   \n",
      "55       SGD        0.10000        0  1.000000e-04     True        256   \n",
      "56       SGD        0.10000      0.9  1.000000e-08    False         64   \n",
      "57       SGD        0.10000      0.9  1.000000e-08    False        256   \n",
      "58       SGD        0.10000      0.9  1.000000e-08     True         64   \n",
      "59       SGD        0.10000      0.9  1.000000e-08     True        256   \n",
      "60       SGD        0.10000      0.9  1.000000e-04    False         64   \n",
      "61       SGD        0.10000      0.9  1.000000e-04    False        256   \n",
      "62       SGD        0.10000      0.9  1.000000e-04     True         64   \n",
      "63       SGD        0.10000      0.9  1.000000e-04     True        256   \n",
      "64   RMSprop        0.00001        0  1.000000e-08    False         64   \n",
      "65   RMSprop        0.00001        0  1.000000e-08    False        256   \n",
      "66   RMSprop        0.00001        0  1.000000e-08     True         64   \n",
      "67   RMSprop        0.00001        0  1.000000e-08     True        256   \n",
      "68   RMSprop        0.00001        0  1.000000e-04    False         64   \n",
      "69   RMSprop        0.00001        0  1.000000e-04    False        256   \n",
      "70   RMSprop        0.00001        0  1.000000e-04     True         64   \n",
      "71   RMSprop        0.00001        0  1.000000e-04     True        256   \n",
      "72   RMSprop        0.00001      0.9  1.000000e-08    False         64   \n",
      "73   RMSprop        0.00001      0.9  1.000000e-08    False        256   \n",
      "74   RMSprop        0.00001      0.9  1.000000e-08     True         64   \n",
      "75   RMSprop        0.00001      0.9  1.000000e-08     True        256   \n",
      "76   RMSprop        0.00001      0.9  1.000000e-04    False         64   \n",
      "77   RMSprop        0.00001      0.9  1.000000e-04    False        256   \n",
      "78   RMSprop        0.00001      0.9  1.000000e-04     True         64   \n",
      "79   RMSprop        0.00001      0.9  1.000000e-04     True        256   \n",
      "80   RMSprop        0.10000        0  1.000000e-08    False         64   \n",
      "81   RMSprop        0.10000        0  1.000000e-08    False        256   \n",
      "82   RMSprop        0.10000        0  1.000000e-08     True         64   \n",
      "83   RMSprop        0.10000        0  1.000000e-08     True        256   \n",
      "84   RMSprop        0.10000        0  1.000000e-04    False         64   \n",
      "85   RMSprop        0.10000        0  1.000000e-04    False        256   \n",
      "86   RMSprop        0.10000        0  1.000000e-04     True         64   \n",
      "87   RMSprop        0.10000        0  1.000000e-04     True        256   \n",
      "88   RMSprop        0.10000      0.9  1.000000e-08    False         64   \n",
      "89   RMSprop        0.10000      0.9  1.000000e-08    False        256   \n",
      "90   RMSprop        0.10000      0.9  1.000000e-08     True         64   \n",
      "91   RMSprop        0.10000      0.9  1.000000e-08     True        256   \n",
      "92   RMSprop        0.10000      0.9  1.000000e-04    False         64   \n",
      "93   RMSprop        0.10000      0.9  1.000000e-04    False        256   \n",
      "94   RMSprop        0.10000      0.9  1.000000e-04     True         64   \n",
      "95   RMSprop        0.10000      0.9  1.000000e-04     True        256   \n",
      "\n",
      "    Test Loss  Test Accuracy  \n",
      "0    0.275761         0.9228  \n",
      "1    0.440706         0.8909  \n",
      "2    0.271751         0.9250  \n",
      "3    0.441161         0.8936  \n",
      "4    0.277587         0.9222  \n",
      "5    0.435497         0.8934  \n",
      "6    0.271417         0.9244  \n",
      "7    0.433867         0.8920  \n",
      "8    0.279488         0.9205  \n",
      "9    0.433815         0.8907  \n",
      "10   0.273649         0.9218  \n",
      "11   0.437840         0.8899  \n",
      "12   0.281203         0.9228  \n",
      "13   0.437088         0.8920  \n",
      "14   0.275861         0.9237  \n",
      "15   0.430950         0.8924  \n",
      "16   2.318328         0.0980  \n",
      "17   1.511103         0.4030  \n",
      "18   2.027071         0.2065  \n",
      "19   1.389302         0.4344  \n",
      "20   2.353147         0.1029  \n",
      "21   1.180892         0.5204  \n",
      "22   2.309464         0.1010  \n",
      "23   1.785378         0.3199  \n",
      "24   2.323086         0.1010  \n",
      "25   1.612432         0.3794  \n",
      "26   2.032931         0.2020  \n",
      "27   1.696283         0.3344  \n",
      "28   2.319948         0.1135  \n",
      "29   1.757098         0.2893  \n",
      "30   2.315045         0.1136  \n",
      "31   1.706632         0.3330  \n",
      "32   2.319410         0.0700  \n",
      "33   2.295231         0.1255  \n",
      "34   2.285572         0.1703  \n",
      "35   2.317484         0.0722  \n",
      "36   2.283019         0.1631  \n",
      "37   2.295017         0.1171  \n",
      "38   2.278287         0.1123  \n",
      "39   2.290445         0.0773  \n",
      "40   2.270882         0.1421  \n",
      "41   2.327280         0.0979  \n",
      "42   2.294528         0.1060  \n",
      "43   2.343536         0.0988  \n",
      "44   2.302181         0.1546  \n",
      "45   2.322287         0.1118  \n",
      "46   2.316478         0.1143  \n",
      "47   2.340034         0.0650  \n",
      "48   0.075327         0.9746  \n",
      "49   0.129228         0.9599  \n",
      "50   0.073058         0.9767  \n",
      "51   0.133840         0.9578  \n",
      "52   0.072548         0.9761  \n",
      "53   0.131608         0.9605  \n",
      "54   0.075574         0.9765  \n",
      "55   0.135103         0.9585  \n",
      "56   0.081119         0.9742  \n",
      "57   0.133224         0.9589  \n",
      "58   0.070178         0.9777  \n",
      "59   0.135808         0.9594  \n",
      "60   0.073003         0.9778  \n",
      "61   0.139541         0.9580  \n",
      "62   0.072707         0.9780  \n",
      "63   0.133580         0.9594  \n",
      "64   0.286662         0.9202  \n",
      "65   0.442207         0.8909  \n",
      "66   0.278105         0.9212  \n",
      "67   0.438158         0.8908  \n",
      "68   0.290271         0.9199  \n",
      "69   0.468218         0.8864  \n",
      "70   0.293087         0.9184  \n",
      "71   0.473287         0.8848  \n",
      "72   0.284735         0.9195  \n",
      "73   0.439645         0.8904  \n",
      "74   0.276888         0.9208  \n",
      "75   0.443636         0.8892  \n",
      "76   0.293617         0.9165  \n",
      "77   0.465657         0.8853  \n",
      "78   0.294079         0.9178  \n",
      "79   0.481343         0.8835  \n",
      "80   1.834359         0.2860  \n",
      "81   1.842889         0.2705  \n",
      "82   1.518065         0.4474  \n",
      "83   1.833208         0.2902  \n",
      "84   1.690437         0.3784  \n",
      "85   1.881383         0.2887  \n",
      "86   2.061680         0.2046  \n",
      "87   1.378038         0.4931  \n",
      "88   2.310856         0.1135  \n",
      "89   1.814215         0.2839  \n",
      "90   1.847276         0.3510  \n",
      "91   1.920444         0.3843  \n",
      "92   1.684004         0.3284  \n",
      "93   1.411910         0.4688  \n",
      "94   1.678212         0.3630  \n",
      "95   1.366880         0.4715  \n"
     ]
    }
   ],
   "source": [
    "# mnist_mlp.py + different regularization techniques\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Define hyperparameter values to test\n",
    "learning_rates = [0.00001, 0.1]\n",
    "momentum_values = [0, 0.9]\n",
    "epsilon_values = [1e-8, 1e-4]\n",
    "nesterov_values = [False, True]\n",
    "batch_sizes = [64, 256]\n",
    "optimizers = [keras.optimizers.Adam, keras.optimizers.SGD, keras.optimizers.RMSprop]\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "results = pd.DataFrame(columns=['Optimizer', 'Learning Rate', 'Momentum', 'Epsilon', 'Nesterov', 'Batch Size', 'Test Loss', 'Test Accuracy'])\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Test different hyperparameters\n",
    "for optimizer in optimizers:\n",
    "    for lr in learning_rates:\n",
    "        for momentum in momentum_values:\n",
    "            for epsilon in epsilon_values:\n",
    "                for nesterov in nesterov_values:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        model = Sequential()\n",
    "                        model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "                        model.add(Dropout(0.2))\n",
    "                        model.add(Dense(512, activation='relu'))\n",
    "                        model.add(Dropout(0.2))\n",
    "                        model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "                        optimizer_name = optimizer.__name__\n",
    "                        optimizer_instance = optimizer(learning_rate=lr)\n",
    "\n",
    "                        if optimizer_name == 'SGD':\n",
    "                            optimizer_instance.momentum = momentum\n",
    "                            optimizer_instance.nesterov = nesterov\n",
    "                        elif optimizer_name == 'RMSprop':\n",
    "                            optimizer_instance.epsilon = epsilon\n",
    "\n",
    "                        model.compile(loss='categorical_crossentropy',\n",
    "                                      optimizer=optimizer_instance,\n",
    "                                      metrics=['accuracy'])\n",
    "\n",
    "                        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=5, verbose=0, validation_data=(x_test, y_test))\n",
    "                        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "                        new_result = pd.DataFrame({'Optimizer': [optimizer_name], 'Learning Rate': [lr], 'Momentum': [momentum], 'Epsilon': [epsilon], 'Nesterov': [nesterov], 'Batch Size': [batch_size], 'Test Loss': [score[0]], 'Test Accuracy': [score[1]]})\n",
    "                        results = pd.concat([results, new_result], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Display the results\n",
    "pd.set_option('display.max_rows', None)  # To display all rows\n",
    "pd.set_option('display.max_columns', None)  # To display all columns\n",
    "best_results = results.sort_values(by='Test Accuracy', ascending=False).head(5)\n",
    "print(\"Top 5 Best Performing Configurations:\")\n",
    "print(best_results)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b214caf",
   "metadata": {},
   "source": [
    "# Parameters results:\n",
    "- Initialization method: GlorotUniform \n",
    "- Activation function: Relu\n",
    "- Optimizer: RMSdrop\n",
    "- Regulazation technique: Dropout\n",
    "- Optimizer + hyperparameters (Learning rate, momentum, epsilon, nesterov, batch size): SGD, 0.1, 0.9, 1.000000e-04, True, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee002b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
